{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‚ô¶Ô∏è I wish you to stay healthy. Your character,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Les bases de l'algorithmique b Darija vos rema...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Corona restrictions causing terrible financial...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üì£üì£AMAZON recrute des conseillers clients √† Dom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great illustration....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  label\n",
       "0  ‚ô¶Ô∏è I wish you to stay healthy. Your character,...      0\n",
       "1  Les bases de l'algorithmique b Darija vos rema...      0\n",
       "2  Corona restrictions causing terrible financial...      0\n",
       "3  üì£üì£AMAZON recrute des conseillers clients √† Dom...      1\n",
       "4                             Great illustration....      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV_COLUMN_NAMES = ['description','label']\n",
    "data = pd.read_csv('data.csv',names=CSV_COLUMN_NAMES, header=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stopwords = {''}\n",
    "Stopwords_fr=set(stopwords.words('french'))\n",
    "Stopwords_eng = set(stopwords.words('english'))\n",
    "add_stop_words = \"all almost also any because cause could do does done don't end for never see soon sorry than ourselves hers between yourself ut again there about once during out very having with they own an be some for do its yours such into of most itself other off is s am for who as from him each the themselves until below are we these your his through don nor me were her more himself this down should our their while above both up to ours had she all no when at any before them same and been have in will on does yourselves then that because what over why so can did not now under he you herself has just where too only myself which those i after few whom t being if theirs my against a by doing it how further was here than a √† √¢ abord afin ah ai aie ainsi allaient allo all√¥ allons apr√®s assez attendu au aucun aucune aujourd aujourd'hui auquel aura auront aussi autre autres aux auxquelles auxquels avaient avais avait avant avec avoir ayant b bah beaucoup bien bigre boum bravo brrr c √ßa car ce ceci cela celle celle-ci celle-l√† celles celles-ci celles-l√† celui celui-ci celui-l√† cent cependant certain certaine certaines certains certes ces cet cette ceux ceux-ci ceux-l√† chacun chaque cher ch√®re ch√®res chers chez chiche chut ci cinq cinquantaine cinquante cinquanti√®me cinqui√®me clac clic combien comme comment compris concernant contre couic crac d da dans de debout dedans dehors del√† depuis derri√®re des d√®s d√©sormais desquelles desquels dessous dessus deux deuxi√®me deuxi√®mement devant devers devra diff√©rent diff√©rente diff√©rentes diff√©rents dire divers diverse diverses dix dix-huit dixi√®me dix-neuf dix-sept doit doivent donc dont douze douzi√®me dring du duquel durant e effet eh elle elle-m√™me elles elles-m√™mes en encore entre envers environ es √®s est et etant √©taient √©tais √©tait √©tant etc √©t√© etre √™tre eu euh eux eux-m√™mes except√© f fa√ßon fais faisaient faisant fait feront fi flac floc font g gens h ha h√© hein h√©las hem hep hi ho hol√† hop hormis hors hou houp hue hui huit huiti√®me hum hurrah i il ils importe j je jusqu jusque k l la l√† laquelle las le lequel les l√®s lesquelles lesquels leur leurs longtemps lorsque lui lui-m√™me m ma maint mais malgr√© me m√™me m√™mes merci mes mien mienne miennes miens mille mince moi moi-m√™me moins mon moyennant n na ne n√©anmoins neuf neuvi√®me ni nombreuses nombreux non nos notre n√¥tre n√¥tres nous nous-m√™mes nul o o| √¥ oh oh√© ol√© oll√© on ont onze onzi√®me ore ou o√π ouf ouias oust ouste outre p paf pan par parmi partant particulier particuli√®re particuli√®rement pas pass√© pendant personne peu peut peuvent peux pff pfft pfut pif plein plouf plus plusieurs plut√¥t pouah pour pourquoi premier premi√®re premi√®rement pr√®s proche psitt puisque q qu quand quant quanta quant-√†-soi quarante quatorze quatre quatre-vingt quatri√®me quatri√®mement que quel quelconque quelle quelles quelque quelques quelqu'un quels qui quiconque quinze quoi quoique r revoici revoil√† rien s sa sacrebleu sans sapristi sauf se seize selon sept septi√®me sera seront ses si sien sienne siennes siens sinon six sixi√®me soi soi-m√™me soit soixante son sont sous stop suis suivant sur surtout t ta tac tant te t√© tel telle tellement telles tels tenant tes tic tien tienne tiennes tiens toc toi toi-m√™me ton touchant toujours tous tout toute toutes treize trente tr√®s trois troisi√®me troisi√®mement trop tsoin tsouin tu u un une unes uns v va vais vas v√© vers via vif vifs vingt vivat vive vives vlan voici voil√† vont vos votre v√¥tre v√¥tres vous vous-m√™mes vu w x y z zut\"\n",
    "add_stop_words = add_stop_words.split()\n",
    "Stopwords.update(add_stop_words)\n",
    "Stopwords.update(Stopwords_fr)\n",
    "Stopwords.update(Stopwords_eng)\n",
    "\n",
    "def stemSentence(sentence):\n",
    "    token_words=word_tokenize(str(sentence))\n",
    "    token_words\n",
    "    porter = PorterStemmer()\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(porter.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)\n",
    "\n",
    "punctuations = string.punctuation #+\"‚Äô¬∂‚Ä¢@¬∞¬©¬Æ‚Ñ¢\"\n",
    "\n",
    "def funct(text):\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    translator = str.maketrans(punctuations,\" \"*len(punctuations))\n",
    "    s = text.translate(translator)\n",
    "    \n",
    "    res = ''.join([i for i in s if not i.isdigit()])\n",
    "    \n",
    "    wordtokens = word_tokenize(res)\n",
    "    \n",
    "    return  ' '.join([w for w in wordtokens if not w in Stopwords])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['description']= data['description'].apply(stemSentence)\n",
    "data['description']=data['description'].apply(funct)\n",
    "\n",
    "freq = pd.Series(' '.join(data['description']).split()).value_counts()[:3]\n",
    "data['description'] = data['description'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "Y = data.pop('label')\n",
    "X = vectorizer.fit_transform(data['description'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8110"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "584/584 [==============================] - 0s 844us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 2/150\n",
      "584/584 [==============================] - 0s 359us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 3/150\n",
      "584/584 [==============================] - 0s 371us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 4/150\n",
      "584/584 [==============================] - 0s 362us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 5/150\n",
      "584/584 [==============================] - 0s 374us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 6/150\n",
      "584/584 [==============================] - 0s 365us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 7/150\n",
      "584/584 [==============================] - 0s 394us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 8/150\n",
      "584/584 [==============================] - 0s 383us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 9/150\n",
      "584/584 [==============================] - 0s 394us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 10/150\n",
      "584/584 [==============================] - 0s 372us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 11/150\n",
      "584/584 [==============================] - 0s 377us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 12/150\n",
      "584/584 [==============================] - 0s 403us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 13/150\n",
      "584/584 [==============================] - 0s 389us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 14/150\n",
      "584/584 [==============================] - 0s 415us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 15/150\n",
      "584/584 [==============================] - 0s 388us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 16/150\n",
      "584/584 [==============================] - 0s 369us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 17/150\n",
      "584/584 [==============================] - 0s 374us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 18/150\n",
      "584/584 [==============================] - ETA: 0s - loss: 8.5587 - accuracy: 0.44 - 0s 401us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 19/150\n",
      "584/584 [==============================] - 0s 379us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 20/150\n",
      "584/584 [==============================] - 0s 365us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 21/150\n",
      "584/584 [==============================] - 0s 389us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 22/150\n",
      "584/584 [==============================] - 0s 441us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 23/150\n",
      "584/584 [==============================] - 0s 396us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 24/150\n",
      "584/584 [==============================] - 0s 403us/step - loss: 8.4543 - accuracy: 0.44860s - loss: 8.6888 - accuracy: \n",
      "Epoch 25/150\n",
      "584/584 [==============================] - 0s 391us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 26/150\n",
      "584/584 [==============================] - 0s 394us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 27/150\n",
      "584/584 [==============================] - 0s 388us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 28/150\n",
      "584/584 [==============================] - 0s 439us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 29/150\n",
      "584/584 [==============================] - 0s 475us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 30/150\n",
      "584/584 [==============================] - 0s 458us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 31/150\n",
      "584/584 [==============================] - 0s 432us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 32/150\n",
      "584/584 [==============================] - 0s 449us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 33/150\n",
      "584/584 [==============================] - 0s 435us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 34/150\n",
      "584/584 [==============================] - 0s 405us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 35/150\n",
      "584/584 [==============================] - 0s 482us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 36/150\n",
      "584/584 [==============================] - 0s 451us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 37/150\n",
      "584/584 [==============================] - 0s 396us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 38/150\n",
      "584/584 [==============================] - 0s 372us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 39/150\n",
      "584/584 [==============================] - 0s 359us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 40/150\n",
      "584/584 [==============================] - 0s 350us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 41/150\n",
      "584/584 [==============================] - 0s 352us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 42/150\n",
      "584/584 [==============================] - 0s 357us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 43/150\n",
      "584/584 [==============================] - 0s 364us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 44/150\n",
      "584/584 [==============================] - 0s 350us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 45/150\n",
      "584/584 [==============================] - 0s 357us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 46/150\n",
      "584/584 [==============================] - 0s 359us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 47/150\n",
      "584/584 [==============================] - 0s 424us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 48/150\n",
      "584/584 [==============================] - 0s 471us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 49/150\n",
      "584/584 [==============================] - 0s 430us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 50/150\n",
      "584/584 [==============================] - 0s 422us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 51/150\n",
      "584/584 [==============================] - 0s 393us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 52/150\n",
      "584/584 [==============================] - 0s 410us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 53/150\n",
      "584/584 [==============================] - 0s 376us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 54/150\n",
      "584/584 [==============================] - 0s 420us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 55/150\n",
      "584/584 [==============================] - 0s 396us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 56/150\n",
      "584/584 [==============================] - 0s 391us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 57/150\n",
      "584/584 [==============================] - 0s 393us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 58/150\n",
      "584/584 [==============================] - 0s 400us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 59/150\n",
      "584/584 [==============================] - 0s 388us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 60/150\n",
      "584/584 [==============================] - 0s 389us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 61/150\n",
      "584/584 [==============================] - 0s 394us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 62/150\n",
      "584/584 [==============================] - 0s 401us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 63/150\n",
      "584/584 [==============================] - 0s 386us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 64/150\n",
      "584/584 [==============================] - 0s 379us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 65/150\n",
      "584/584 [==============================] - 0s 400us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 66/150\n",
      "584/584 [==============================] - 0s 391us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 67/150\n",
      "584/584 [==============================] - 0s 383us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 68/150\n",
      "584/584 [==============================] - 0s 391us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 69/150\n",
      "584/584 [==============================] - 0s 422us/step - loss: 8.4543 - accuracy: 0.44860s - loss: 8.4136 - accuracy: 0.\n",
      "Epoch 70/150\n",
      "584/584 [==============================] - 0s 435us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 71/150\n",
      "584/584 [==============================] - 0s 444us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 72/150\n",
      "584/584 [==============================] - 0s 417us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 73/150\n",
      "584/584 [==============================] - 0s 388us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 74/150\n",
      "584/584 [==============================] - 0s 398us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 75/150\n",
      "584/584 [==============================] - 0s 401us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 76/150\n",
      "584/584 [==============================] - 0s 406us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 77/150\n",
      "584/584 [==============================] - 0s 393us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 78/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "584/584 [==============================] - 0s 372us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 79/150\n",
      "584/584 [==============================] - 0s 374us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 80/150\n",
      "584/584 [==============================] - 0s 350us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 81/150\n",
      "584/584 [==============================] - 0s 362us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 82/150\n",
      "584/584 [==============================] - 0s 383us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 83/150\n",
      "584/584 [==============================] - 0s 412us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 84/150\n",
      "584/584 [==============================] - 0s 424us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 85/150\n",
      "584/584 [==============================] - 0s 381us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 86/150\n",
      "584/584 [==============================] - 0s 345us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 87/150\n",
      "584/584 [==============================] - 0s 432us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 88/150\n",
      "584/584 [==============================] - 0s 357us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 89/150\n",
      "584/584 [==============================] - 0s 355us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 90/150\n",
      "584/584 [==============================] - 0s 357us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 91/150\n",
      "584/584 [==============================] - 0s 359us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 92/150\n",
      "584/584 [==============================] - 0s 362us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 93/150\n",
      "584/584 [==============================] - 0s 355us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 94/150\n",
      "584/584 [==============================] - 0s 372us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 95/150\n",
      "584/584 [==============================] - 0s 350us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 96/150\n",
      "584/584 [==============================] - 0s 383us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 97/150\n",
      "584/584 [==============================] - 0s 369us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 98/150\n",
      "584/584 [==============================] - 0s 365us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 99/150\n",
      "584/584 [==============================] - 0s 357us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 100/150\n",
      "584/584 [==============================] - 0s 359us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 101/150\n",
      "584/584 [==============================] - 0s 352us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 102/150\n",
      "584/584 [==============================] - 0s 350us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 103/150\n",
      "584/584 [==============================] - 0s 348us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 104/150\n",
      "584/584 [==============================] - 0s 364us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 105/150\n",
      "584/584 [==============================] - 0s 360us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 106/150\n",
      "584/584 [==============================] - 0s 350us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 107/150\n",
      "584/584 [==============================] - 0s 357us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 108/150\n",
      "584/584 [==============================] - 0s 360us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 109/150\n",
      "584/584 [==============================] - 0s 369us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 110/150\n",
      "584/584 [==============================] - 0s 360us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 111/150\n",
      "584/584 [==============================] - 0s 357us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 112/150\n",
      "584/584 [==============================] - 0s 362us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 113/150\n",
      "584/584 [==============================] - 0s 364us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 114/150\n",
      "584/584 [==============================] - 0s 354us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 115/150\n",
      "584/584 [==============================] - 0s 348us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 116/150\n",
      "584/584 [==============================] - 0s 367us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 117/150\n",
      "584/584 [==============================] - 0s 357us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 118/150\n",
      "584/584 [==============================] - 0s 360us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 119/150\n",
      "584/584 [==============================] - 0s 384us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 120/150\n",
      "584/584 [==============================] - 0s 369us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 121/150\n",
      "584/584 [==============================] - 0s 357us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 122/150\n",
      "584/584 [==============================] - 0s 359us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 123/150\n",
      "584/584 [==============================] - 0s 365us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 124/150\n",
      "584/584 [==============================] - 0s 406us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 125/150\n",
      "584/584 [==============================] - 0s 355us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 126/150\n",
      "584/584 [==============================] - 0s 357us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 127/150\n",
      "584/584 [==============================] - 0s 357us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 128/150\n",
      "584/584 [==============================] - 0s 369us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 129/150\n",
      "584/584 [==============================] - 0s 352us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 130/150\n",
      "584/584 [==============================] - 0s 360us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 131/150\n",
      "584/584 [==============================] - 0s 357us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 132/150\n",
      "584/584 [==============================] - 0s 352us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 133/150\n",
      "584/584 [==============================] - 0s 372us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 134/150\n",
      "584/584 [==============================] - 0s 376us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 135/150\n",
      "584/584 [==============================] - 0s 355us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 136/150\n",
      "584/584 [==============================] - 0s 350us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 137/150\n",
      "584/584 [==============================] - 0s 350us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 138/150\n",
      "584/584 [==============================] - 0s 360us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 139/150\n",
      "584/584 [==============================] - 0s 357us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 140/150\n",
      "584/584 [==============================] - 0s 359us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 141/150\n",
      "584/584 [==============================] - 0s 367us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 142/150\n",
      "584/584 [==============================] - 0s 357us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 143/150\n",
      "584/584 [==============================] - 0s 427us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 144/150\n",
      "584/584 [==============================] - 0s 379us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 145/150\n",
      "584/584 [==============================] - 0s 359us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 146/150\n",
      "584/584 [==============================] - 0s 360us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 147/150\n",
      "584/584 [==============================] - 0s 377us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 148/150\n",
      "584/584 [==============================] - 0s 369us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 149/150\n",
      "584/584 [==============================] - 0s 355us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "Epoch 150/150\n",
      "584/584 [==============================] - 0s 354us/step - loss: 8.4543 - accuracy: 0.4486\n",
      "147/147 [==============================] - 0s 407us/step\n",
      "Accuracy: 49.66\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim = X.shape[1] , activation='relu'))\n",
    "model.add(Dense(30 , activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, epochs=150, batch_size=10)\n",
    "\n",
    "_, accuracy = model.evaluate(X_test, Y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = \"We are looking for an experienced Audit professional in our Audit Department as ‚ÄúAssistant Manager - Operations‚Äù to be responsible for operational audits at the group level. Qualification: (CA / ACCA / CMA) Qualified / Finalist Experience: (Articles completed from Big four + 1 to 2 yrs of Operations audit experience) OR (5 yrs of Operational audit experience in FMCG or manufacturing concern) To: nasir.ahmed@dawn-group.com Mention Position in Subject Line Last date to apply: 18-04-2020\"\n",
    "#text = stemSentence(text)\n",
    "#text = funct(text)\n",
    "#text = vectorizer.fit_transform([text])\n",
    "#classes = model.predict(text, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
